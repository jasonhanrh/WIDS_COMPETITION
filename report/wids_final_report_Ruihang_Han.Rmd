---
title: "WiDS Datathon++ 2025: Predicting Brain Age and Exploring Sex Differences"
author: "Your Team Name"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    number_sections: true
    toc_depth: 3
    theme: flatly
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
library(GGally)
library(ggmosaic)
library(corrplot)

# Load Dataset
train_df <- read.csv("train_df.csv")
set.seed(42)
```

# 1. Introduction

Understanding how brain networks develop differently between males and females during childhood and adolescence is critical to identifying sex-specific vulnerabilities to neuropsychiatric disorders. The WiDS Datathon++ 2025 challenges participants to model brain age using resting-state functional connectivity data and to explore sex-based differences in model behavior and neurodevelopmental patterns.

In this study, we aim to predict chronological age from high-dimensional fMRI-derived connectome features and associated metadata in a population of children and adolescents aged 5 to 21. Each subject’s brain is represented as a 200×200 functional connectivity matrix, vectorized into \~20,000 features, and enriched with demographic, behavioral, and psychological information (e.g., sex, BMI, factor scores).

We employ multiple machine learning approaches, including Ridge regression and XGBoost, to build accurate age prediction models. To reduce dimensionality and improve interpretability, we apply Principal Component Analysis (PCA) and Lasso-based variable selection. We then conduct a detailed analysis of sex-specific differences in model performance, feature contributions, and brain network patterns, using tools such as residual diagnostics, SHAP values, partial dependence plots, and connectome-based network analysis.

Our goal is twofold: (1) to achieve robust brain-age prediction and (2) to uncover interpretable sex differences in functional brain development, contributing to a better understanding of normative and atypical trajectories during youth.

# 2. Data and Preprocessing

The training dataset comprises 1,104 adolescent participants aged 5 to 21 years, each associated with two key data sources: (1) a functional connectome matrix derived from resting-state fMRI scans, and (2) rich metadata including demographic, physiological, and mental health factors. Each connectome is a 200×200 symmetric matrix representing pairwise correlation between 200 brain regions. To reduce dimensionality and ensure modeling compatibility, only the upper triangular portion of the matrix was extracted and flattened into a feature vector of approximately 19,900 elements per participant.

## 2.1 Parallel Extraction of Brain Connectivity Features

To efficiently process the large number of `.tsv` files in the `train_tsv` directory, we implemented a parallelized pipeline using the `furrr` and `future` packages. Each file corresponds to one subject and contains their 200×200 functional connectivity matrix.

```{r}
# Parallel extraction from .tsv files
plan(multisession, workers = parallel::detectCores())

# Load and extract upper-triangular connectome vectors
extract_tsv_row <- function(file) {
  pid <- str_extract(basename(file), "(?<=sub-)[^_]+")
  mat <- tryCatch(read_tsv(file, col_names = FALSE, progress = FALSE) %>% as.matrix(), error = function(e) NULL)
  if (is.null(mat)) return(NULL)
  vec <- mat[upper.tri(mat)]
  tibble(participant_id = pid, !!!set_names(as.list(vec), paste0("V", seq_along(vec))))
}

# Apply in parallel to valid .tsv files
train_features <- future_map(valid_files, extract_tsv_row, .progress = TRUE) %>%
  compact() %>%
  bind_rows()
```

The output is a dataframe where each row corresponds to a participant and each column `V1` to `V19900+` represents a correlation between two brain regions. This structure captures the functional architecture of the brain in a high-dimensional feature space.

## 2.2 Merging with Metadata

After extracting connectivity features, we merged the results with the corresponding metadata from `training_metadata.csv`. Metadata fields include age (target variable), sex, race, ethnicity, BMI, parental education, handedness, study site, and four z-scored psychological factors (p-factor, internalizing, externalizing, attention).

```{r}
# Merge brain features with metadata
train_df <- train_features %>%
  inner_join(train_meta, by = "participant_id")

# Save final dataset
write_csv(train_df, "train_df.csv")
saveRDS(train_df, "train_df.rds")
```

This process yielded a modeling-ready dataset (`train_df`) with 1,104 participants and nearly 20,000 features. The final object was stored both as CSV and compressed `.rds` for faster downstream access.

## 2.3 Data Structure and Missing Values

We conducted a structural check of the merged dataset to verify dimensions, column types, and missingness.

```{r}
dim(train_df)
table(sapply(train_df, class))
```

The dataset contains 1,104 rows and 20,000+ columns, primarily composed of numeric features from the connectome and a combination of numeric and categorical metadata.

Missing value analysis revealed that:

```{r}
total_missing <- sum(is.na(train_df))
missing_ratio <- total_missing / (nrow(train_df) * ncol(train_df))
cat("Total missing values:", total_missing, "\n")
cat("Missing ratio:", round(missing_ratio * 100, 2), "%\n")

missing_cols <- colSums(is.na(train_df))
missing_cols[missing_cols > 0] %>% sort(decreasing = TRUE) %>% head(10)
```

Only 500 values were missing (\<0.01% overall). These were mostly limited to metadata fields like `parent_1_education`, `race`, and `ethnicity`. During preprocessing, continuous variables (e.g., BMI) were imputed using the median, while missing levels in categorical variables were handled by creating an explicit `"Missing"` category, preserving potential patterns related to nonresponse.

This pipeline effectively combined:

-   Scalable parallel extraction of functional connectivity features,
-   Rich metadata integration, and
-   Targeted missing value handling.

The resulting dataset was ready for dimensionality reduction, encoding, and predictive modeling in the next phase of the analysis.

# 3. Exploratory Data Analysis (EDA)

## 3.1 Demographic Variable Distributions

We began by examining categorical metadata to understand the demographic makeup of the dataset. Frequency counts and bar plots reveal the distribution across variables such as sex, race, handedness, study site, and parental education.

```{r}
# Frequency counts
list(
  sex = table(train_df$sex),
  race = table(train_df$race),
  handedness = table(train_df$handedness),
  study_site = table(train_df$study_site),
  ethnicity = table(train_df$ethnicity),
  parent_1_education = table(train_df$parent_1_education),
  parent_2_education = table(train_df$parent_2_education)
)
```

```{r}
# Visual summaries
ggplot(train_df, aes(x = sex)) + geom_bar(fill = "#66c2a5") + labs(title = "Sex Distribution") + theme_minimal()
ggplot(train_df, aes(x = race)) + geom_bar(fill = "#fc8d62") + labs(title = "Race Distribution") + theme_minimal()
ggplot(train_df, aes(x = handedness)) + geom_bar(fill = "#8da0cb") + labs(title = "Handedness Distribution") + theme_minimal()
ggplot(train_df, aes(x = study_site)) + geom_bar(fill = "#e78ac3") + labs(title = "Study Site Distribution") + theme_minimal()
ggplot(train_df, aes(x = parent_1_education)) + geom_bar(fill = "darkgreen") + labs(title = "Parent 1 Education", x = "Education Level") + theme(axis.text.x = element_text(angle = 45)) + theme_minimal()
```

The dataset reveals a moderate gender imbalance (688 males vs. 416 females), and a predominantly right-handed population. White is the most common race, followed by Other, Black, and Asian groups. Most participants were recruited from HBNsiteRU and HBNsiteCBIC, while parental education levels skew toward tertiary completion. The dataset shows a gender imbalance, with more male participants (688) than female (416). In terms of race, the majority identify as White (530), followed by Other (210), Black (157), and Asian (39), with some missing values. The handedness distribution is heavily skewed toward right-handed individuals (954), with fewer left-handed (121) and ambidextrous (29) participants. Most data were collected from two major study sites, HBNsiteRU and HBNsiteCBIC, while HBNsiteCUNY contributed the fewest. Regarding parental education, a large portion of Parent 1 had completed tertiary education (562), and similarly high levels were observed for Parent 2. Ethnicity data indicates most participants are not Hispanic or Latino (712), while 283 are identified as Hispanic or Latino.

We examined potential interactions between sex and race using a mosaic plot:

```{r}
ggplot(data = train_df) +
  geom_mosaic(aes(weight = 1, x = product(sex), fill = race)) +
  labs(title = "Mosaic Plot: Sex vs Race", x = "Sex", fill = "Race") +
  theme_minimal()
```

Race distribution is largely consistent across sex categories. White participants are the majority in both groups, followed by Other and Black. This consistency suggests minimal interaction between race and sex in this sample.

## 3.2 Summary Statistics of Continuous Variables

We summarized key continuous variables—age, BMI, and standardized psychological factors—using descriptive statistics.

```{r}
numeric_summary <- train_df %>%
  select(age, bmi, p_factor_fs, internalizing_fs, externalizing_fs, attention_fs) %>%
  summary()
numeric_summary
```

Participants range in age from approximately 5 to 22 years (mean ≈ 11.2), with BMI spanning from 12.6 to 46.1. Mental health scores are z-scored and exhibit moderate variability. The distributions provide a foundation for modeling age while accounting for psychological and developmental diversity.

All psychological factor scores are z-scored, with mean values close to 0, as expected. The p-factor, a general psychopathology indicator, shows a range from -1.61 to 2.98. Internalizing and externalizing scores (e.g., anxiety/depression vs. behavioral dysregulation) also vary broadly, from -2.26 to 2.82 and -2.15 to 4.24, respectively. The attention factor spans from -3.18 to 2.48, with slightly more negative skew. These distributions reflect moderate psychological variability across participants and support the use of these variables as covariates or predictors in modeling brain age. The presence of 18 missing BMI values will need to be addressed via imputation or exclusion strategies in downstream analysis.

## 3.3 Age and BMI Trends

To explore growth and health patterns, we examined age and BMI trends across sex and race groups using histograms, scatterplots, and boxplots.

```{r}
# Age by sex
ggplot(train_df, aes(x = age, fill = as.factor(sex))) +
  geom_histogram(position = "dodge", bins = 30) +
  labs(title = "Age Distribution by Sex", x = "Age", fill = "Sex") +
  theme_minimal()

# BMI vs Age
ggplot(train_df, aes(x = age, y = bmi, color = as.factor(sex))) +
  geom_point(alpha = 0.5) +
  labs(title = "BMI vs Age by Sex", x = "Age", y = "BMI", color = "Sex") +
  theme_minimal()

# BMI by Race
ggplot(train_df, aes(x = race, y = bmi, fill = race)) +
  geom_boxplot() +
  labs(title = "BMI Distribution by Race") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))
```

The age distribution is slightly right-skewed, with most participants concentrated between ages 8 and 13. Males outnumber females at nearly every age, consistent with the overall sex imbalance observed earlier.

The BMI scatterplot reveals a general upward trend with age, reflecting natural growth and weight gain. Both sexes show a similar trajectory, though male participants are slightly more represented in the higher BMI range at older ages.

The boxplot of BMI by race shows meaningful variation across groups. Asian participants tend to have the lowest median BMI and narrower spread, whereas Black participants display higher median BMI and greater variability, including more high-end outliers. These patterns may reflect differences in body composition, socioeconomic factors, or access to healthcare and nutrition.

## 3.4 Psychological Factors and Group Differences

om mood- and behavior-related symptoms.

The density plots along the diagonal show that all variables are approximately normally distributed with mild deviations.

```{r}
# Mean psychological scores by sex
train_df %>%
  group_by(sex) %>%
  summarise(across(c(p_factor_fs, internalizing_fs, externalizing_fs, attention_fs), mean, na.rm = TRUE)) %>%
  pivot_longer(-sex, names_to = "Factor", values_to = "Mean_Score") %>%
  ggplot(aes(x = Factor, y = Mean_Score, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Mental Health Scores by Sex") +
  theme_minimal()
```

The bar chart displays the average scores of four standardized psychological factors by sex: general psychopathology (`p_factor_fs`), internalizing symptoms (e.g., anxiety and depression), externalizing behaviors (e.g., aggression and rule-breaking), and attention-related difficulties (e.g., inattention and hyperactivity). Clear differences emerge across sexes:

-   **Females** exhibit higher mean values in both the `p_factor_fs` and `internalizing_fs` domains, suggesting a greater burden of generalized emotional symptoms and internal distress.

-   **Males** score higher in `externalizing_fs` and, most notably, in `attention_fs`, indicating that behavioral dysregulation and attentional difficulties are more prevalent among male participants.

The negative mean `attention_fs` score among females contrasts sharply with the positive score among males, which is consistent with developmental psychology literature. Studies have shown that males are more likely to exhibit overt behavioral symptoms such as hyperactivity and impulsivity, while females tend to present with more internalized symptoms. These sex-linked patterns provide strong justification for stratifying modeling outcomes by sex in subsequent analyses and underscore the potential for differential neurodevelopmental trajectories between males and females.

```{r}
# Attention score by sex
ggplot(train_df, aes(x = sex, y = attention_fs, fill = sex)) +
  geom_boxplot() +
  labs(title = "Attention Score by Sex", x = "Sex", y = "Attention Factor Score") +
  theme_minimal()

# Age vs P-factor
ggplot(train_df, aes(x = age, y = p_factor_fs)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(title = "Age vs P-Factor", y = "P-Factor") +
  theme_minimal()
```

The boxplot shows that males have higher attention factor scores than females, both in terms of median and overall range. Male participants display more variability and a greater number of high outliers, indicating more pronounced attention-related difficulties. In contrast, female scores are generally lower and more tightly distributed, suggesting fewer symptoms of inattention or hyperactivity.

The scatterplot of age and p-factor scores shows little to no relationship between the two. The trend line is flat, indicating that general psychological distress levels remain stable across the sampled age range.

## 3.5 Correlation Matrix of Continuous Predictors

We constructed a correlation heatmap across key continuous predictors to identify linear dependencies and potential multicollinearity:

```{r}
selected_vars <- train_df %>%
  select(age, bmi, p_factor_fs, internalizing_fs, externalizing_fs, attention_fs)

cor_matrix <- cor(selected_vars, use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "lower", addCoef.col = "black", number.cex = 0.7,
         title = "Correlation Matrix of Selected Variables", mar = c(0, 0, 1, 0))
```

Age and BMI show a moderate positive correlation (r = 0.51), which is consistent with expected growth patterns. The psychological scores—p-factor, internalizing, externalizing, and attention—are only weakly correlated with each other and with age or BMI. This indicates that they represent distinct constructs and can be modeled independently without strong concern for multicollinearity.

## 3.6 PCA of Brain Connectivity Features

To explore the structure of high-dimensional functional connectivity features, we applied Principal Component Analysis (PCA) to the set of connectome variables. PCA provides a reduced-dimensional representation that captures the most salient variance in the data, making it useful for visualizing broad patterns such as potential grouping by sex.

```{r}
brain_data <- train_df %>% select(starts_with("V"))
pca_result <- prcomp(brain_data, center = TRUE, scale. = TRUE)
pca_df <- as.data.frame(pca_result$x[, 1:2])
pca_df$sex <- train_df$sex

ggplot(pca_df, aes(x = PC1, y = PC2, color = sex)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "2D PCA Projection of Brain Functional Connectivity",
    x = "Principal Component 1",
    y = "Principal Component 2",
    color = "Sex"
  ) +
  theme_minimal()
```

The PCA projection onto the first two components reveals substantial overlap between sexes, with no clear clustering or boundary that separates male and female participants. This suggests that sex does not account for large-scale variance in the dominant principal components. Instead, brain connectivity patterns appear to be more individually distributed or may vary along more subtle dimensions not captured in PC1 and PC2. This visual result supports the need for more nuanced modeling approaches when analyzing sex-related brain connectivity differences.

# 4. Modeling and Prediction

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
set.seed(42)
```

## 4.1 Package Loading

m a preprocessed `.rds` file. To evaluate model performance, we split the data into training (80%) and validation (20%) sets using stratified sampling based on the `sex` variable to preserve group proportions in both subsets.

```{r}
df <- readRDS("train_df.rds")
train_idx <- createDataPartition(df$sex, p = 0.8, list = FALSE)
train <- df[train_idx, ]
valid <- df[-train_idx, ]
```


# Determine number of components to retain 90% cumulative variance
n_pcs_90 <- which(cum_explained >= 0.90)[1]
cat("Number of principal components to retain:", n_pcs_90, "\n")

# Transform training and validation sets using the top components
train_pc <- as_tibble(pcs$x[, 1:n_pcs_90])
valid_pc <- predict(pcs, select(valid, starts_with("V")) %>%
                    scale(center = pcs$center, scale = pcs$scale))[, 1:n_pcs_90] %>%
                    as_tibble()

```


      across(c(sex, race, study_site, handedness, parent_1_education), ~ fct_na_value_to_level(factor(.), "Missing"))
    )
}
encode <- function(data) model.matrix(~ . -1, data = data)

train_meta <- prepare_meta(train)
valid_meta <- prepare_meta(valid)

train_meta_enc <- bind_cols(as_tibble(encode(train_meta %>% select(-participant_id))), tibble(participant_id = train_meta$participant_id))
valid_meta_enc <- bind_cols(as_tibble(encode(valid_meta %>% select(-participant_id))), tibble(participant_id = valid_meta$participant_id))
```

## 4.5 Merging PCA Features and Metadata


To identify the most informative predictors among the metadata variables, we applied Lasso regression with 10-fold cross-validation. Lasso imposes an L1 penalty, shrinking less important coefficients toward zero and effectively performing variable selection. This approach helps reduce overfitting and improves model interpretability by eliminating redundant or weakly associated features. The selected variables were retained for use in subsequent modeling steps involving metadata-PCA integration.

```{r}
# Extract metadata features (excluding participant ID)
X_train_meta <- train_meta_enc %>% select(-participant_id)
X_meta_mat <- as.matrix(X_train_meta)

# Perform Lasso regression with 10-fold cross-validation
cv_lasso <- cv.glmnet(

# Display selected metadata features
cat("Selected metadata features:\n")
print(lasso_selected)

```

Lasso regression identified six metadata variables with non-zero coefficients at the optimal penalty level. These included `bmi`, `externalizing_fs`, `attention_fs`, one study site indicator (`HBNsiteRU`), and two levels of parental education. The selected features represent a combination of individual clinical assessments and sociodemographic context, suggesting that both biological and environmental factors contribute to brain age prediction. These variables were retained in subsequent models to improve parsimony and interpretability.

## 4.7 Ridge Regression

###
  alpha = 0,                     # alpha = 0 for Ridge
  nfolds = 10,                   # number of folds
  foldid = foldid,               # use predefined fold IDs
  standardize = TRUE,           # standardize predictors
  type.measure = "mse"          # use mean squared error as metric
)

# Make predictions on the validation set using optimal lambda
ridge_pred <- predict(cv_ridge, newx = X_valid_mat, s = "lambda.min") %>% as.vector()

# Calculate RMSE for Ridge predictions
ridge_rmse <- rmse(y_valid, ridge_pred)
cat("Ridge regression validation RMSE:", round(ridge_rmse, 4), "\n")

# Visualize predicted vs actual values
ridge_plot <- ggplot(data.frame(Predicted = ridge_pred, Actual = y_valid), aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.5) +
  g relationships in the feature space.

### 4.7.2 PCA + Lasso-Selected Metadata

To improve model parsimony and potentially enhance generalization, we re-estimated the Ridge regression using only the metadata features selected by the Lasso procedure. These reduced metadata variables were combined with the same PCA-derived connectome components used previously. This selective feature approach aimed to reduce noise and emphasize variables with stronger predictive signals.

```{r}
# Select metadata features identified by Lasso

  type.measure = "mse"
)

# Predict on validation set using the model with optimal lambda
ridge_lasso_pca_pred <- predict(cv_ridge_lasso_pca, newx = X_valid_lasso_pca_mat, s = "lambda.min") %>% as.vector()

# Calculate RMSE
ridge_lasso_pca_rmse <- rmse(y_valid, ridge_lasso_pca_pred)
cat("Ridge (Lasso Metadata + PCA) validation RMSE:", round(ridge_lasso_pca_rmse, 4), "\n")

```

# Initialize list to store predictions for each fold
ridge_preds <- list()

# Train Ridge model on each fold and predict on the full validation set
for (i in seq_along(folds)) {
  fold_valid_idx <- folds[[i]]
  
  # Use remaining folds for training
  X_tr <- X_train_lasso_pca[-fold_valid_idx, ]
  y_tr <- y_train[-fold_valid_idx]
  
  # Fit Ridge model on current training fold
  ridge_model <- cv.glmnet(as.matrix(X_tr), y_tr, alpha = 0, nfolds = 5)
  
  # Predict on full validation set
  ridge_pred <- predict(ridge_model, newx = as.matrix(X_valid_lasso_pca), s = "lambda.min") %>% as.vector()
  
  # Store prediction
  ridge_preds[[i]] <- ridge_pred
}


The predicted-versus-actual scatter plot shows improved alignment with the ideal diagonal line, particularly for mid-range age values. The slope of the fitted trend line is steeper than in previous Ridge models, indicating better calibration across the range of predicted ages. These results highlight the benefit of fold-wise ensembling for increasing robustness and generalization in linear models.

## 4.8 XGBoost with Bayesian Optimization

To capture nonlinear relationships and improve predictive accuracy, we implemented an XGBoost regression model with hyperparameter tuning via Bayesian Optimization. XGBoost is a gradient-boosted decision tree algorithm known for its performance and flexibility. Rather than using grid or random search, we adopted Bayesian Optimization to efficiently explore the hyperparameter space, focusing on the learning rate (`eta`) and tree depth (`max_depth`). Model performance was monitored using RMSE on the validation set.

```{r}
# Load required libraries
library(xgboost)
library(ParBayesianOptimization)

# Set seed for reproducibility
set.seed(42)

# Prepare training and validation sets in DMatrix format
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dvalid <- xgb.DMatrix(data = as.matrix(X_valid), label = y_valid)

# Define the objective function for Bayesian optimization
bayes_xgb_function <- function(eta, max_depth) {
  set.seed(42)  # Ensure reproducible results in each iteration
  params <- list(
    booster = "gbtree",
    objective = "reg:squarederror",
    eval_metric = "rmse",
    tree_method = "hist",
    eta = eta,
    max_depth = as.integer(max_depth),
    subsample = 0.8,
    colsample_bytree = 0.8
  )
  
  # Train model and return negative RMSE for maximization
  model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 100,
    watchlist = list(valid = dvalid),
    early_stopping_rounds = 10,
    verbose = 0
  )
  
  list(Score = -rmse(y_valid, predict(model, dvalid)))
}


  )

# Residual plot for Ensemble model
resid_ensemble <- y_valid - (best_w * ridge_lasso_pca_pred + (1 - best_w) * xgb_pred)

ggplot(data.frame(Residual = resid_ensemble), aes(x = Residual)) +
  geom_histogram(bins = 30, fill = "darkgreen", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Ensemble Model Residual Distribution",
    x = "Residual (Actual - Predicted)",
    y = "Count"
  )

```


# Statistical tests for Ridge residuals by sex
t.test(Ridge_Resid ~ sex, data = valid_preds)        # Parametric
wilcox.test(Ridge_Resid ~ sex, data = valid_preds)   # Non-parametric

```

To further evaluate model performance across sex, we examined the distribution of residuals for Ridge and XGBoost models. The residual density plots reveal a leftward shift in the male distribution compared to females, particularly in the Ridge model, suggesting that male participants' ages were more likely to be underestimated. In contrast, the XGBoost model showed narrower residual spreads and less pronounced differences between groups.

To formally test for group differences in residuals, both Welch’s t-test and the non-parametric Wilcoxon rank-sum test were conducted for the Ridge model. The p-values from these tests (0.0878 and 0.0839, respectively) provide marginal evidence of a difference in prediction error distributions between male and female participants. While not statistically significant at the conventional 5% level, the consistent pattern across tests supports the observation of potential sex-specific prediction bias, particularly under linear modeling assumptions.

### 5.1.5 RMSE by Age Group

To investigate whether model performance varies by age group and sex, the validation set is stratified into four developmental age ranges. Within each subgroup, we calculate the Root Mean Squared Error (RMSE) for Ridge and XGBoost models. The resulting grouped RMSE values are visualized using bar plots, faceted by model type, to facilitate comparison of age-specific prediction accuracy across sexes.

```{r}
# Create age groups and compute RMSE within each group and sex
valid_preds <- valid_preds %>%
  mu
               names_to = "Model",
               values_to = "RMSE")

# Bar plot of RMSE by age group and sex
ggplot(age_rmse, aes(x = AgeGroup, y = RMSE, fill = sex)) +

# Extract first 5 PCs and attach sex label
pc_df <- as_tibble(predict(pcs,
                           select(valid, starts_with("V")))[, 1:5]) %>%
  mutate(sex = valid$sex)

# Plot density for each PC
for (i in 1:5) {
  p <- ggplot(pc_df,
              aes_string(x = paste0("PC", i), color = "sex")) +
    geom_density(alpha = 0.5) +
    labs(title = paste0("Density of PC", i, " by Sex")) +
    theme_minimal()
  print(p)
}

```

We examined the distribution of the top five principal components by sex to assess potential structural differences in connectome space. PC1 and PC2 show noticeable shifts between male and female distributions, with males generally exhibiting lower values on PC1. Smaller but consistent differences are also observed in PC3 to PC5, suggesting sex-related variation in the underlying connectivity features.

### 5.2.2 Statistical Tests on Principal Components

To formally assess whether the distributions of the principal components differ significantly by sex, we conduct two-sample t-tests for each of the first five PCs. The resulting p-values are reported to quantify the evidence of sex-based separability in the learned connectome embeddings.

```{r}
# Perform t-test for each PC
pc_tests <- map_df(1:5, function(i) {
  t_result <- t.test(pc_df[[paste0("PC", i)]] ~ pc_df$sex)
  tibble(PC = paste0("PC", i), p.value = t_result$p.value)
})

# Display p-values
print(pc_tests)

```

To formally test for sex-based differences in the connectome-derived feature space, we conducted two-sample t-tests on the top five principal components. The results reveal a statistically significant difference in PC1 (p = 0.0106), indicating that this component captures meaningful variation associated with sex. No significant differences were found in PC2 through PC5 (all p \> 0.23), suggesting that the sex effect is primarily concentrated in the leading principal axis.

## 5.3 Feature Importance Comparison (PDP & SHAP)

### 5.3.1 PDP of BMI by Sex (Ridge Regression)

To explore whether the influence of individual predictors differs by sex, we employ partial dependence plots (PDPs) to visualize the marginal effect of BMI on predicted age under sex-specific Ridge regression models. By fitting separate models for males and females, we isolate and compare the shape and slope of the BMI-age relationship, helping to reveal any potential sex-dependent heterogeneity in predictive structure.

```{r}
X_train_male <- train_merged %>% filter(participant_id %in% train$participant_id[train$sex == "Male"]) %>% select(-participant_id)
X_train_female <- train_merged %>% filter(participant_id %in% train$participant_id[train$sex == "Female"]) %>% select(-participant_id)

y_train_male <- train %>% filter(sex == "Male") %>% pull(age)
y_train_female <- train %>% filter(sex == "Female") %>% pull(age)

ridge_male <- cv.glmnet(as.matrix(X_train_male), y_train_male, alpha = 0)
ridge_female <- cv.glmnet(as.matrix(X_train_female), y_train_female, alpha = 0)

ridge_pred_fun <- function(object, newdata) {
  predict(object, newx = as.matrix(newdata), s = "lambda.min")
}

pdp_male <- partial(ridge_male, pred.var = "bmi", train = as.data.frame(X_train_male), grid.resolution = 20, pred.fun = ridge_pred_fun)
pdp_female <- partial(ridge_female, pred.var = "bmi", train = as.data.frame(X_train_female), grid.resolution = 20, pred.fun = ridge_pred_fun)

bind_rows(
  pdp_male %>% mutate(Sex = "Male"),
  pdp_female %>% mutate(Sex = "Female")
) %>%
  ggplot(aes(x = bmi, y = yhat, color = Sex)) +
  geom_line(size = 1) +
  labs(title = "PDP of BMI by Sex (Ridge Regression)", x = "BMI", y = "Predicted Age") +
  theme_minimal()
```

The PDP illustrates the marginal effect of BMI on predicted age across sex-specific Ridge regression models. While both curves exhibit an overall positive relationship, the predicted age for females is consistently higher than that for males at corresponding BMI levels. This suggests that BMI may have a more pronounced association with predicted age in females under the Ridge modeling framework.

### 5.3.2 SHAP Summary for XGBoost by Sex

To complement the linear interpretation offered by Ridge PDPs, we further evaluate feature importance using SHAP (SHapley Additive exPlanations) values from sex-specific XGBoost models. SHAP values decompose each prediction into additive contributions from each feature, enabling a fair and consistent measure of global feature impact. We report and compare the top 10 most influential features for each sex, highlighting any divergence in feature prioritization between groups.

```{r}
# Prepare DMatrix for male/female XGBoost models
dtrain_male   <- xgb.DMatrix(data = as.matrix(X_train_male),   label = y_train_male)
dtrain_female <- xgb.DMatrix(data = as.matrix(X_train_female), label = y_train_female)

# Define XGBoost parameters
params <- list(
  booster           = "gbtree",
  objective         = "reg:squarederror",
  eval_metric       = "rmse",
  eta               = 0.1,
  max_depth         = 4,
  subsample         = 0.8,
  colsample_bytree  = 0.8
)

# Train separate XGBoost models
xgb_male   <- xgb.train(params, dtrain_male,   nrounds = 200)
xgb_female <- xgb.train(params, dtrain_female, nrounds = 200)

# Compute SHAP values for each model
shap_male   <- shap.values(xgb_model = xgb_male,   X_train = as.matrix(X_train_male))
shap_female <- shap.values(xgb_model = xgb_female, X_train = as.matrix(X_train_female))

# Extract top 10 features by mean |SHAP| score
top10_male   <- sort(shap_male$mean_shap_score,   decreasing = TRUE)[1:10]
top10_female <- sort(shap_female$mean_shap_score, decreasing = TRUE)[1:10]

# Combine for plotting
shap_long <- bind_rows(
  tibble(Feature = names(top10_male),   SHAP = top10_male,   Sex = "Male"),
  tibble(Feature = names(top10_female), SHAP = top10_female, Sex = "Female")
)

# Plot SHAP value comparison
ggplot(shap_long, aes(x = reorder(Feature, SHAP), y = SHAP, fill = Sex)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Top 10 SHAP Features by Sex (XGBoost)",
       x = "Feature", y = "Mean |SHAP Value|") +
  theme_minimal()

```

The SHAP summary plot reveals the top predictors of age for each sex under the XGBoost model. BMI consistently emerged as the most influential feature for both males and females, followed by principal components such as PC1 and PC19. While there is general overlap in the top features across sexes, certain components (e.g., PC19, PC11) show sex-specific prominence, suggesting subtle differences in how feature importance contributes to model predictions.

## 5.4 Connectome Differences and Network Visualization

### 5.4.1 Heatmap of Connectivity Differences

To quantify neural connectivity differences between sexes, we compute and contrast the mean connectome vectors for male and female participants. These vectors are reconstructed into symmetric adjacency matrices and differenced to yield a sex-specific connectivity difference matrix. The resulting matrix is visualized as a heatmap, enabling identification of brain regions with elevated or diminished average connectivity across sex.

```{r}
# Extract connectome features for valid participants
valid_feats <- df %>%
  filter(participant_id %in% valid_merged$participant_id) %>%
  select(participant_id, sex, starts_with("V"))

# Compute mean connectivity vector by sex
male_mean_vec   <- valid_feats %>% filter(sex == "Male")   %>% select(starts_with("V")) %>% summarise_all(mean) %>% unlist()
female_mean_vec <- valid_feats %>% filter(sex == "Female") %>% select(starts_with("V")) %>% summarise_all(mean) %>% unlist()

# Recover adjacency matrix dimension
n <- as.integer((sqrt(8 * length(male_mean_vec) + 1) + 1) / 2)

# Build symmetric difference matrix
diff_vec <- male_mean_vec - female_mean_vec
diff_mat <- matrix(0, n, n)
diff_mat[upper.tri(diff_mat)] <- diff_vec
diff_mat <- diff_mat + t(diff_mat) - diag(diag(diff_mat))

# Visualize as heatmap
Heatmap(diff_mat, name = "Male–Female\nConnectivity")

```

The heatmap illustrates the difference in mean connectome connectivity between males and females across all brain region pairs. Warm colors (red) indicate higher average connectivity in males, while cool colors (blue) indicate stronger connectivity in females. The symmetric pattern and hierarchical clustering reveal broad but heterogeneous sex-specific differences in functional brain organization.

### 5.4.2 Subnetwork of Top Differences

To highlight the most salient structural differences, we extract the 50 connectome edges with the largest absolute sex-based discrepancies. We then construct a subgraph consisting of the associated brain regions and visualize this reduced network using a force-directed layout. Edge width and color encode the magnitude of difference, offering an interpretable and compact representation of key structural divergences.

```{r}
# Create full graph from difference matrix
g_full <- graph_from_adjacency_matrix(diff_mat,
                                      mode = "undirected",
                                      weighted = TRUE,
                                      diag = FALSE)
V(g_full)$name <- as.character(1:vcount(g_full))

# Select top 50 edges by absolute weight
edges_df <- igraph::as_data_frame(g_full, what = "edges") %>%
  as_tibble() %>%
  slice_max(abs(weight), n = 50)

ngs highlight potential regions of interest for future neurobiological investigations into sex-related functional specialization.
est absolute differences in mean connectivity between male and female participants. Notably, the connection between regions 77 and 81 shows the most pronounced sex difference, with an absolute divergence exceeding 0.15. Several other region pairs involving node 61 (e.g., 61–76, 61–78, 61–69) also appear prominently, reinforcing its potential role as a sex-sensitive hub. These findings complement the subnetwork visualization and suggest that specific neural circuits, rather than diffuse patterns, account for most of the observed sex-based connectivity disparities. Such localized differences may be critical for understanding functional specialization in brain development across sexes.

## 5.5 Summary of Sex Differences Findings

Our analysis revealed several notable sex differences in both predictive performance and brain network characteristics. First, while Ridge regression exhibited slightly better RMSE in females, XGBoost showed superior performance in males, suggesting potential disparities in model fit or neurodevelopmental patterns across sexes. Residual distribution plots and statistical tests further indicated that the Ridge model tended to systematically underpredict female ages relative to males.

Principal component analysis (PCA) on connectome features showed a statistically significant difference in the first component (PC1) between sexes, indicating that overall connectome structure partially encodes sex-specific variation. Partial dependence plots (PDP) and SHAP analysis also revealed divergent patterns of feature importance; for example, BMI had a stronger marginal effect on age prediction in males than in females, and different metadata features ranked highest in SHAP importance across sexes.

Finally, comparison of average connectome vectors identified brain regions with the largest sex-specific connectivity differences. A subnetwork of the top 50 connections demonstrated concentrated divergence around specific hubs, such as Node 192 and Node 61, suggesting localized rather than diffuse sex-based structural differences.

Together, these findings support the hypothesis that male and female brain networks follow distinct developmental trajectories during adolescence. This underscores the importance of sex-specific modeling in neurodevelopmental research and highlights potential regions of interest for future investigation into brain-based biomarkers of psychiatric risk.

# 6. Discussion

We constructed predictive models of chronological age using connectome features and metadata, achieving strong performance with both Ridge regression and XGBoost. The ensemble of the two models yielded further improvements, suggesting that both linear and nonlinear patterns contribute meaningfully to brain-age estimation.

A central focus of this study was the analysis of sex-based differences in prediction outcomes. XGBoost outperformed Ridge overall, particularly for male participants, while Ridge exhibited a smaller performance gap between sexes. Residual distributions and statistical tests indicated mild but consistent sex differences, with Ridge residuals skewed higher for females, suggesting potential prediction bias.

To further investigate these discrepancies, we analyzed the PCA feature space and found that the first principal component significantly differed by sex, reflecting structural variation in brain connectivity. Additional interpretation via partial dependence plots and SHAP values revealed sex-specific differences in feature influence—most notably for BMI and certain principal components—highlighting the role of distinct covariate effects in each group.

At the network level, connectome analysis showed that sex-related differences were concentrated in a limited set of connections rather than globally distributed. These differences were often centered around hub-like nodes, suggesting localized rather than uniform divergence in functional development between sexes.

Taken together, these findings underscore subtle yet consistent sex-based heterogeneity in both prediction performance and neurobiological structure, with potential implications for personalized approaches in neurodevelopmental research and clinical modeling.

# 7. Conclusion and Future Work

This study explored the prediction of chronological brain age using resting-state functional connectivity data and metadata in a large youth sample. By combining PCA-reduced connectome features with curated metadata, we evaluated multiple modeling approaches—including Ridge regression, XGBoost, and their ensemble variants. Among these, the stacking ensemble achieved the best generalization performance (validation RMSE = 1.7359), outperforming individual models and highlighting the value of combining linear and non-linear learners.

Beyond predictive performance, we conducted a detailed analysis of sex-based differences. XGBoost showed stronger overall performance, particularly for males, while Ridge regression exhibited smaller performance gaps but a slight bias toward underpredicting female age. PCA revealed a significant difference in the first principal component by sex, suggesting structural variation in connectome space. SHAP and partial dependence analyses further uncovered distinct patterns of feature importance between males and females—particularly for BMI and select connectivity components. Connectome-level comparisons identified a small subset of brain region pairs with consistent sex-based connectivity differences, suggesting that developmental divergence is localized rather than global.

Taken together, these findings demonstrate that high-dimensional neuroimaging data, when combined with metadata and ensemble modeling, can yield accurate age predictions and uncover subtle, biologically meaningful group differences. Future work may extend this approach by incorporating longitudinal data, exploring fairness-aware modeling, or leveraging deep learning to capture more complex temporal and spatial patterns in brain development.

# 8. Appendix

To ensure reproducibility and provide transparency on the computational environment, we include the full R session information below:

```{r}
sessionInfo()
```
